# Data Manipulation with dplyr

Say you've found a great dataset and would like to learn more about it. How can you start to answer the questions you have about the data? You can use dplyr to answer those questions—it can also help with basic transformations of your data. You'll also learn to aggregate your data and add, remove, or change the variables. Along the way, you'll explore a dataset containing information about counties in the United States. You'll finish the course by applying these tools to the babynames dataset to explore trends of baby names in the United States.

## Transforming Data with dplyr
Learn verbs you can use to transform your data, including select, filter, arrange, and mutate. You'll use these functions to modify the counties dataset to view particular observations and answer questions about the data.

### Video: The counties dataset

### Question: Understanding your data

#### Load the `counties` data set and the `dplyr` package
```{r}
counties <- read.csv("data_acs2015_county_data.csv")
library("dplyr")
```
Take a look at the `counties` dataset using the `glimpse()` function.

```{r}
glimpse(counties)
```

### Selecting columns
Select the following four columns from the `counties` variable:

- `state`
- `county`
- `population`
- `poverty`

You don't need to save the result to a variable.

#### Select the columns 
```{r, eval=TRUE, results = 'hide'}
counties %>%
  select(state, county, population, poverty)
```

Recall that if you want to keep the data you've selected, you can use assignment to create a new table.

### Video: The filter and arrange verbs

### Arranging observations
Here you see the `counties_selected dataset` with a few interesting variables selected. These variables: `private_work`, `public_work`, `self_employed` describe whether people work for the government, for private companies, or for themselves.

In these exercises, you'll sort these observations to find the most interesting cases.

```{r}
counties_selected <- counties %>%
  select(state, county, population, private_work, public_work, self_employed)
```


#### Add a verb to sort in descending order of public_work
```{r, eval=TRUE, results = 'hide'}
counties_selected %>%
  arrange(desc(public_work))
```

We sorted the counties in descending order according to `public_work`. What if we were interested in looking at observations in counties that have a large population or within a specific state? Let's take a look at that next!

### Filtering for conditions
You use the `filter()` verb to get only observations that match a particular condition, or match multiple conditions.

```{r}
counties_selected <- counties %>%
  select(state, county, population)
```

#### Filter for counties with a population above 1000000
```{r, eval=TRUE, results = 'hide'}
counties_selected %>%
  filter(population > 1000000)
```

#### Filter for counties in the state of California that have a population above 1000000
```{r}
counties_selected %>%
  filter(state == "California",
         population > 1000000)
```

Now you know that there are 9 counties in the state of California with a population greater than one million. In the next exercise, you'll practice filtering and then sorting a dataset to focus on specific observations!

### Filtering and arranging
We're often interested in both filtering and sorting a dataset, to focus on observations of particular interest to you. Here, you'll find counties that are extreme examples of what fraction of the population works in the private sector.

```{r}
counties_selected <- counties %>%
  select(state, county, population, private_work, public_work, self_employed)
```

#### Filter for Texas and more than 10000 people; sort in descending order of private_work
```{r}
counties_selected %>%
  filter(state == "Texas", population > 10000) %>%
  arrange(desc(private_work))
```

You've learned how to filter and sort a dataset to answer questions about the data. Notice that you only need to slightly modify your code if you are interested in sorting the observations by a different column.

### Video: Mutate

### Calculating the number of government employees
In the video, you used the `unemployment` variable, which is a percentage, to calculate the number of unemployed people in each county. In this exercise, you'll do the same with another percentage variable: `public_work`.

The code provided already selects the `state`, `county`, `population`, and `public_work` columns.

```{r}
counties_selected <- counties %>%
  select(state, county, population, public_work)
```


#### Sort in descending order of the public_workers column
```{r, eval=TRUE, results = 'hide'}
counties_selected %>%
  mutate(public_workers = public_work * population / 100) %>%
  arrange(desc(public_workers))
```

It looks like Los Angeles is the county with the most government employees.

### Calculating the percentage of women in a county
The dataset includes columns for the total number (not percentage) of men and women in each county. You could use this, along with the `population` variable, to compute the fraction of men (or women) within each county.

In this exercise, you'll select the relevant columns yourself.

#### Select the columns state, county, population, men, and women
```{r}
counties_selected <- counties %>%
  select(state, county, population, men, women)
```


#### Calculate proportion_women as the fraction of the population made up of women
```{r, eval=TRUE, results = 'hide'}
counties_selected %>%
  mutate(proportion_women = women / population)
```

Notice that the `proportion_women` variable was added as a column to the `counties_selected` dataset, and the data now has 6 columns instead of 5.

### Select, mutate, filter, and arrange
In this exercise, you'll put together everything you've learned in this chapter (`select()`, `mutate()`, `filter()` and `arrange()`), to find the counties with the highest proportion of men.

```{r, eval=TRUE}
counties %>%
  # Select the five columns 
  select(state, county, population, men, women) %>%
  # Add the proportion_men variable
  mutate(proportion_men = men / population) %>%
  # Filter for population of at least 10,000
  filter(population >= 10000) %>%
  # Arrange proportion of men in descending order 
  arrange(desc(proportion_men)) 
```

Notice Sussex County in Virginia is more than two thirds male: this is because of two men's prisons in the county.

---

## Aggregating Data
Now that you know how to transform your data, you'll want to know more about how to aggregate your data to make it more interpretable. You'll learn a number of functions you can use to take many observations in your data and summarize them, including count, group_by, summarize, ungroup, and top_n.

### Video: The count verb

### Counting by region
The counties dataset contains columns for region, state, population, and the number of citizens, which we selected and saved as the `counties_selected` table. In this exercise, you'll focus on the `region` column.

```{r}
counties_selected <- counties %>%
  select(region, state, population, citizens)
```

#### Use count to find the number of counties in each region
```{r}
counties_selected %>%
  count(region, sort=TRUE)
```

Since the results have been arranged, you can see that the South has the greatest number of counties.

### Counting citizens by state
You can weigh your count by particular variables rather than finding the number of counties. In this case, you'll find the number of citizens in each state.

```{r}
counties_selected <- counties %>%
  select(region, state, population, citizens)
```

#### Find number of counties per state, weighted by citizens
```{r}
counties_selected %>%
count(state, wt=citizens, sort=TRUE)
```

From our result, we can see that California is the state with the most citizens.

### Mutating and counting
You can combine multiple verbs together to answer increasingly complicated questions of your data. For example: "What are the US states where the most people walk to work?"

You'll use the walk column, which offers a percentage of people in each county that walk to work, to add a new column and count based on it.

```{r}
counties_selected <- counties %>%
  select(state, population, walk)
```

```{r}
counties_selected %>%
  # Add population_walk containing the total number of people who walk to work 
  mutate(population_walk = population * walk / 100) %>%
  # Count weighted by the new column
  count(state, wt = population_walk, sort=TRUE)
```

We can see that while California had the largest total population, New York state has the largest number of people who walk to work.

### Video: The group by, summarize and ungroup verbs

#### Summarizing
The `summarize()` verb is very useful for collapsing a large dataset into a single observation.

```{r}
counties_selected <- counties %>%
  select(county, population, income, unemployment)
```

#### Summarize to find minimum population, maximum unemployment, and average income
```{r}
counties_selected %>%
  summarise(min_population = min(population), max_unemployment = max(unemployment), average_income = mean(income))
```

If we wanted to take this a step further, we could use `filter()` to determine the specific counties that returned the value for `min_population` and `max_unemployment`.

```{r}
counties_selected %>% 
  filter(population == min(population))

counties_selected %>% 
  filter(unemployment == max(unemployment))
```

### Summarizing by state
Another interesting column is `land_area`, which shows the land area in square miles. Here, you'll summarize both population and land area by state, with the purpose of finding the density (in people per square miles).

```{r}
counties_selected <- counties %>%
  select(state, county, population, land_area)
```

#### Add a density column, then sort in descending order
```{r}
counties_selected %>%
  group_by(state) %>%
  summarize(total_area = sum(land_area),
            total_population = sum(population)) %>%
  mutate(density = total_population / total_area) %>%
  arrange(desc(density))
```

Looks like New Jersey and Rhode Island are the “most crowded” of the US states, with more than a thousand people per square mile.

### Summarizing by state and region
You can group by multiple columns instead of grouping by one. Here, you'll practice aggregating by state and region, and notice how useful it is for performing multiple aggregations in a row.

```{r}
counties_selected <- counties %>%
  select(region, state, county, population)
```

#### Calculate the average_pop and median_pop columns 
```{r}
counties_selected %>%
  group_by(region, state) %>%
  summarize(total_pop = sum(population)) %>%
  summarize(average_pop = mean(total_pop), median_pop = median(total_pop))
```

It looks like the South has the highest `average_pop` of 7370486, while the North Central region has the highest `median_pop` of 5580644.

### Video: The top_n verb

### Selecting a county from each region
Previously, you used the `walk` column, which offers a percentage of people in each county that walk to work, to add a new column and count to find the total number of people who walk to work in each county.

Now, you're interested in finding the county within each region with the highest percentage of citizens who walk to work.

```{r}
counties_selected <- counties %>%
  select(region, state, county, metro, population, walk)
```

#### Group by region and find the greatest number of citizens who walk to work
```{r}
counties_selected %>%
  group_by(region) %>%
  top_n(1, walk)
```

Notice that three of the places lots of people walk to work are low-population nonmetro counties, but that New York City also pops up!

### Finding the highest-income state in each region
You've been learning to combine multiple `dplyr` verbs together. Here, you'll combine `group_by()`, `summarize()`, and `top_n()` to find the state in each region with the highest income.

When you group by multiple columns and then summarize, it's important to remember that the summarize "peels off" one of the groups, but leaves the rest on. For example, if you `group_by(X, Y)` then `summarize`, the result will still be grouped by `X`.

```{r}
counties_selected <- counties %>%
  select(region, state, county, population, income)
```

```{r}
counties_selected %>%
  group_by(region, state) %>%
  # Calculate average income
  summarise(average_income = mean(income)) %>%
  # Find the highest income state in each region
  top_n(1, average_income)
```

From our results, we can see that New Jersey in the Northeast is the state with the highest `average_income` of 73014.

### Using summarize, top_n, and count together
In this chapter, you've learned to use five `dplyr` verbs related to aggregation: `count()`, `group_by()`, `summarize()`, `ungroup()`, and `top_n()`. In this exercise, you'll use *all* of them to answer a question: In how many states do more people live in metro areas than non-metro areas?

Recall that the `metro` column has one of the two values "Metro" (for high-density city areas) or "Nonmetro" (for suburban and country areas).

```{r}
counties_selected <- counties %>%
  select(state, metro, population)
```

#### Count the states with more people in Metro or Nonmetro areas
```{r}
counties_selected %>%
  group_by(state, metro) %>%
  summarize(total_pop = sum(population)) %>%
  top_n(1, total_pop) %>%
  ungroup(total_pop) %>%
  count(metro)
```

Notice that 44 states have more people living in Metro areas, and 6 states have more people living in Nonmetro areas.

---

## Selecting and Transforming Data
Learn advanced methods to select and transform columns. Also learn about select helpers, which are functions that specify criteria for columns you want to choose, as well as the rename and transmute verbs.

### Video: Selecting

### Selecting columns
Using the select verb, we can answer interesting questions about our dataset by focusing in on related groups of verbs. The colon (`:`) is useful for getting many columns at a time.

#### Glimpse the counties table
```{r}
glimpse(counties)
```

```{r, eval=TRUE, results = 'hide'}
counties %>%
  # Select state, county, population, and industry-related columns
  select(state, county, population, professional:production) %>%
  # Arrange service in descending order 
  arrange(desc(service))
```

Notice that when you select a group of related variables, it's easy to find the insights you're looking for.

### Select helpers
In the video you learned about the select helper `starts_with()`. Another select helper is `ends_with()`, which finds the columns that end with a particular string.

```{r}
counties %>%
  # Select the state, county, population, and those ending with "work"
  select(state, county, population, ends_with("work")) %>%
  # Filter for counties that have at least 50% of people engaged in public work
  filter(public_work >= 50)
```

It looks like only a few counties have more than half the population working for the government.

### Video: The rename verb

### Renaming a column after count
The `rename()` verb is often useful for changing the name of a column that comes out of another verb, such as` count()`. In this exercise, you'll rename the `n` column from `count()` (which you learned about in Chapter 2) to something more descriptive.

```{r}
# Rename the n column to num_counties
counties %>%
  count(state) %>%
  rename(num_counties = n)
```

Notice the difference between column names in the output from the first step to the second step. Don't forget, using `rename()` isn't the only way to choose a new name for a column!

### Renaming a column as part of a select
`rename()` isn't the only way you can choose a new name for a column: you can also choose a name as part of a `select()`.

```{r, eval=TRUE, results = 'hide'}
# Select state, county, and poverty as poverty_rate
counties %>%
  select(state, county, poverty_rate = poverty)
```

As you can see, we were able to select the four columns of interest from our dataset, and rename one of those columns, using only the `select()` verb!

### Video: The transmute verb

### Question: Choosing among verbs

![](/Users/user/Documents/R/RProgforBus/select_mutate_rename_transmute.png) Source: DataCamp


Recall, you can think of `transmute()` as a combination of `select()` and `mutate()`, since you are getting back a subset of columns, but you are transforming and changing them at the same time.

### Using transmute
As you learned in the video, the transmute verb allows you to control which variables you keep, which variables you calculate, and which variables you drop.

```{r}
counties %>%
  # Keep the state, county, and populations columns, and add a density column
  transmute(state, county, population, density = population / land_area) %>%
  # Filter for counties with a population greater than one million 
  filter(population > 1000000) %>%
  # Sort density in ascending order 
  arrange(density)
```

Looks like San Bernadino is the lowest density county with a population about one million.

```{r}
counties %>%
  # Keep the state, county, and populations columns, and add a density column
  transmute(state, county, population, density = population / land_area) %>%
  # Filter for counties with a population greater than one million 
  filter(population > 1000000) %>%
  # Sort density in ascending order 
  arrange(density)
```

### Question: Matching verbs to their definitions
We've learned a number of new verbs in this chapter that you can use to modify and change the variables you have.

- `rename`: Leaves the column you don't mention alone; doesn't allow you to calculate or change values.
- `transmute`: Must mention all the columns you keep; allows you to calculate or change values.
- `mutate`: Leaves the columns you don't mention alone; allows you to calculate or change values.

Let's continue practising using the verbs to gain a better understanding of the differences between them.

### Choosing among the four verbs
In this chapter you've learned about the four verbs: select, mutate, transmute, and rename. Here, you'll choose the appropriate verb for each situation. You won't need to change anything inside the parentheses.

```{r, eval=TRUE, results = 'hide'}
# Change the name of the unemployment column
counties %>%
  rename(unemployment_rate = unemployment)

# Keep the state and county columns, and the columns containing poverty
counties %>%
  select(state, county, contains("poverty"))

# Calculate the fraction_women column without dropping the other columns
counties %>%
  mutate(fraction_women = women / population)

# Keep only the state, county, and employment_rate columns
counties %>%
  transmute(state, county, employment_rate = employed / population)
```

Now you know which variable to choose depending on whether you want to keep, drop, rename, or change a variable in the dataset.

---

## Case Study: The babynames Dataset
Work with a new dataset that represents the names of babies born in the United States each year. Learn how to use grouped mutates and window functions to ask and answer more complex questions about your data. And use a combination of dplyr and ggplot2 to make interesting graphs to further explore your data.

### Video: The babynames data

```{r}
library(babynames) 
library(dplyr) 
library(tidyr)
```

```{r}
babynames <- babynames %>% 
  select(year, name, n) %>% 
  group_by(year, name) %>% 
  summarise(number = sum(n)) %>% 
  # ungroup() %>% 
  arrange(year, name)
babynames
```

### Filtering and arranging for one year
The dplyr verbs you've learned are useful for exploring data. For instance, you could find out the most common names in a particular year.

```{r}
babynames %>%
  # Filter for the year 1990
  filter(year == 1990) %>%
  # Sort the number column in descending order 
  arrange(desc(number))
```

It looks like the most common names for babies born in the US in 1990 were Michael, Christopher, and Jessica.

### Using top_n with babynames
You saw that you could use `filter()` and `arrange()` to find the most common names in one year. However, you could also use `group_by` and `top_n` to find the most common name in every year.

```{r}
# Find the most common name in each year
babynames %>%
  group_by(year) %>%
  top_n(1, number)
```

It looks like John was the most common name in 1880, and Mary was the most common name for a while after that.

### Visualizing names with ggplot2
The `dplyr` package is very useful for exploring data, but it's especially useful when combined with other `tidyverse` packages like `ggplot2`. (As of tidyverse 1.3.0, the following packages are included in the core tidyverse: `dplyr`, `ggplot2`, `tidyr`, `readr`, `purrr`, `tibble`, `stringr`, `forcats`. To make sure you are able to access the package, install all the packages in the tidyverse by running `install.packages("tidyverse")`, then run `library(tidyverse)` to load the core tidyverse and make it available in your current R session.)

```{r}
# Filter for the names Steven, Thomas, and Matthew 
selected_names <- babynames %>%
  filter(name %in% c("Steven", "Thomas", "Matthew"))

# Plot the names using a different color for each name
ggplot(selected_names, aes(x = year, y = number, color = name)) +
  geom_line()
```

It looks like names like Steven and Thomas were common in the 1950s, but Matthew became common more recently.

### Video: Grouped mutates

### Finding the year each name is most common
In an earlier video, you learned how to filter for a particular name to determine the frequency of that name over time. Now, you're going to explore which year each name was the most common.

To do this, you'll be combining the grouped mutate approach with a `top_n`.

```{r}
# Calculate the fraction of people born each year with the same name
babynames %>%
  group_by(year) %>%
  mutate(year_total = sum(number)) %>%
  ungroup() %>%
  mutate(fraction = number / year_total) %>%
# Find the year each name is most common
  group_by(name) %>%
  top_n(1, fraction)
```

Notice that the results are grouped by `year`, then `name`, so the first few entries are names that were most popular in the 1880's that start with the letter A.

### Adding the total and maximum for each name
In the video, you learned how you could group by the year and use `mutate()` to add a total for that year.

In these exercises, you'll learn to normalize by a different, but also interesting metric: you'll divide each name by the *maximum for that name*. This means that every name will peak at 1.

Once you add new columns, the result will still be grouped by name. This splits it into 48,000 groups, which actually makes later steps like `mutate` slower.

```{r}
babynames %>%
  group_by(name) %>%
  mutate(name_total = sum(number),
         name_max = max(number)) %>%
  # Ungroup the table 
  ungroup() %>%
  # Add the fraction_max column containing the number by the name maximum 
  mutate(fraction_max = number / name_max)
```

This tells you, for example, that the name Abe was at 18.5% of its peak in the year 1880.

### Visualizing the normalized change in popularity
You picked a few names and calculated each of them as a fraction of their peak. This is a type of "normalizing" a name, where you're focused on the relative change within each name rather than the overall popularity of the name.

In this exercise, you'll visualize the normalized popularity of each name. Your work from the previous exercise, `names_normalized`, has been provided for you.

```{r}
names_normalized <- babynames %>%
                     group_by(name) %>%
                     mutate(name_total = sum(number),
                            name_max = max(number)) %>%
                     ungroup() %>%
                     mutate(fraction_max = number / name_max)
```

```{r}
# Filter for the names Steven, Thomas, and Matthew
names_filtered <- names_normalized %>%
  filter(name %in% c("Steven", "Thomas", "Matthew"))
# Visualize these names over time
ggplot(names_filtered, aes(x = year, y = fraction_max, color = name)) +
geom_line()
```

As you can see, the line for each name hits a peak at 1, although the peak year differs for each name.

### Video: Window functions
The code shown at the end of the video (finding the variable `difference` for all names) contains a mistake. Can you spot it? Below is the corrected code.

```{r}
# As we did before, but now naming it babynames_fraction
babynames_fraction <- babynames %>%
  group_by(year) %>% 
  mutate(year_total = sum(number)) %>% 
  ungroup() %>% 
  mutate(fraction = number / year_total)
# Just for Matthew
babynames_fraction %>% 
  filter(name == "Matthew") %>% 
  arrange(year) %>% 
# Display change in prevalence from year to year
  mutate(difference = fraction - lag(fraction)) %>% 
# Arange in descending order
  arrange(desc(difference))
  
# For all names
babynames_fraction %>% 
  group_by(name) %>% 
# Display change in prevalence from year to year
  mutate(difference = fraction - lag(fraction)) %>% 
# Arange in descending order
  arrange(name, year)
```

### Using ratios to describe the frequency of a name
In the video, you learned how to find the difference in the frequency of a baby name between consecutive years. What if instead of finding the difference, you wanted to find the ratio?

You'll start with the `babynames_fraction` data already, so that you can consider the popularity of each name within each year.

```{r}
babynames_ratio <- babynames_fraction %>%
  # Arrange the data in order of name, then year 
  arrange(name, year) %>%
  # Group the data by name
  group_by(name) %>%
  # Add a ratio column that contains the ratio between each year 
  mutate(ratio = fraction / lag(fraction))
```

Notice that the first observation for each name is missing a ratio, since there is no previous year.

### Biggest jumps in a name
Previously, you added a `ratio` column to describe the ratio of the frequency of a baby name between consecutive years to describe the changes in the popularity of a name. Now, you'll look at a subset of that data, called `babynames_ratios_filtered`, to look further into the names that experienced the biggest jumps in popularity in consecutive years.

```{r}
babynames_ratios_filtered <- babynames_ratio %>%
                     filter(fraction >= 0.00001)
```

```{r}
babynames_ratios_filtered %>%
  # Extract the largest ratio from each name 
  top_n(1, ratio) %>%
  # Sort the ratio column in descending order 
  arrange(desc(ratio)) %>%
  # Filter for fractions greater than or equal to 0.001
  filter(fraction >= 0.001)
```

Some of these can be interpreted: for example, Grover Cleveland was a president elected in 1884.

### Video: Contratulations!
You'll find all of these skills valuable is these other DataCamp courses:

- Exploratory Data Analysis in R: Case Study
- Working with Data in the Tidyverse
- Machine Learning in the Tidyverse
- Categorical Data in the Tidyverse

---

## Challenge 

Hey

---

## Solutions

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(dplyr) # Load dplyr package
library(ggplot2) # Load ggplot2 package
library(ds4psy) # Load ds4psy package
```

```{r}
sw <- dplyr::starwars # Create sw dataframe
head(sw)
```

### Question 1

```{r}
dim(sw) # 1.a.

dim.sw <- nrow(sw)*ncol(sw) # 1.b.
```

### Question 2

```{r}
na.cells <- sum(is.na(sw)) # 2.a.

round(100*na.cells/dim.sw,1) # 2.b.

colnames(sw[,colSums(is.na(sw)) == max(colSums(is.na(sw)))]) # 2.c.

filter(sw, is.na(homeworld)==TRUE & (is.na(birth_year)==FALSE | is.na(mass)==FALSE))  # 2.d.
```

### Question 3

```{r}
length(unique(sw$species)) # 3.
```

### Question 4

```{r}
length(which(sw$species == "Human")) # 4.a.i

sw %>% # 4.a.ii.
  filter(species=="Human") %>% 
  group_by(gender) %>% 
  count()

filter(sw, is.na(gender) | (gender != "male" & gender != "female")) %>% # 4.b.
  count()

sw %>% # 4.c.
  group_by(species, gender) %>% # Creates piles of similarly sexed members of the same species
  count() %>% # Produces a table of tallies of the above groups
  group_by(species) %>% # Groups within this table of tallies
  count() %>% # Produces a tally of the numbers of members of the groups above
  filter(n > 1)
```

### Question 5

```{r}
tb <- sw %>% # 5.a.
  group_by(gender) %>% 
  count()

my_cols <- unikn::usecol(c(Pinky, Seegruen, Seeblau, Grau))
ggplot(sw, aes(x = gender)) + # 5.b.
  geom_bar(aes(fill = gender)) +
  labs(title = "Sex distribtion of the sw universe",
       tag = "5.b.",
       x = "Gender",
       y = "Frequency",
       caption = "Using raw data sw.") +
  scale_fill_manual(name = "Gender:", values = my_cols, na.value = "black") +
  ds4psy::theme_ds4psy()

ggplot(tb, aes(x = gender, y = n)) + # 5.c., adding y=n to the aes()
  geom_bar(aes(fill = gender), stat = "identity") + # Adding stat="identity" to the aes()
  labs(title = "Sex distribtion of the sw universe",
       tag = "5.c.",
       x = "Gender",
       y = "Frequency",
       caption = "Using raw data sw.") +
  scale_fill_manual(name = "Gender:", values = my_cols, na.value = "black") +
  ds4psy::theme_ds4psy()
```

### Question 6

```{r}
sw %>% # 6.a.
  group_by(homeworld) %>% 
  count() %>% 
  arrange(desc(n))

sw %>% # 6.b.
  filter(homeworld == "Naboo", eye_color == "orange") %>% 
  summarise(n = n(),
            mn_height =mean(height))
```

### Question 7

```{r}
sw %>% # 7.
  filter(species == "Droid") %>% 
  summarise(n = n(),
            not_NA_h = sum(!is.na(height)),
            md_height = median(height, na.rm=TRUE), 
            mn_height = mean(height, na.rm=TRUE), 
            sd_height = sd(height, na.rm=TRUE))
```

### Question 8

```{r}
h_m <- sw %>% # 8.a.
  group_by(species) %>% 
  summarise(mn_height = mean(height, na.rm=TRUE),
            mn_mass = mean(mass, na.rm=TRUE))

h_m %>% # 8.b.
  arrange(mn_height) %>% 
  slice(1:3) 

h_m %>% # 8.c.
  arrange(desc(mn_mass)) %>% 
  slice(1:3)
```

### Question 9

```{r}
sw %>% # 9.a.
  filter(!is.na(species)) %>% 
  group_by(species) %>% 
  summarise(n = n()) %>% 
  arrange(desc(n)) %>% 
  slice(1:3)

sw %>% # 9.b.
  select(name, homeworld, mass) %>% 
  group_by(homeworld) %>% 
  mutate(mn_mass = mean(mass, na.rm = TRUE),
         lighter = mass < (mn_mass*0.8)
         ) %>% 
  filter(lighter == TRUE)
```

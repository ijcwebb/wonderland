# Exploratory Data Analysis in R

## Comics

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#install.packages("easypackages") # Will install and load packages if not loaded
library(easypackages)
#packages("dplyr", "ggplot2", "openintro", "gapminder", "fivethirtyeight", "downloader", "tidyverse", "tibble")
libraries("dplyr", "ggplot2", "openintro", "gapminder", "fivethirtyeight", "downloader", "tidyverse", "tibble") 
```

In this chapter, you will learn how to create graphical and numerical summaries of two categorical variables.

```{r load comics data set}
url <- "https://assets.datacamp.com/production/course_1796/datasets/comics.csv"
filename <- basename(url)
if (!file.exists(filename)) download(url,destfile=filename)
comics <- read.csv(filename)
# comics %>% 
#  rename(
#    sepal_length = Sepal.Length,
#    sepal_width = Sepal.Width
#    )
```

### Video: Exploring categorical data

[View slides.](https://drive.google.com/drive/folders/1rTSXe2HiLMbTePzcwtP4IUKEOHs-0OXY)

```{r look at comics}
str(comics)
```

```{r contingency table}
levels(comics$align)
levels(comics$id)
table(comics$id, comics$align)
ggplot(comics, aes(x=align, fill=id)) +
  geom_bar()
ggplot(comics, aes(x=id, fill=align)) +
  geom_bar()
```

### Question: Bar chart expectations

<center>

![Which one of the barcharts shows no relationship between `age` and `flavor`? In other words, which shows that pie preference is the same for both young and old? *Source: DataCamp*](/Users/user/Documents/R/RProgforBus/Module7/Comics/barchartexpectations.png){width=80%}

</center>

It's the first one.

### Contingency table review

In this chapter you'll continue working with the `comics` dataset introduced in the video. This is a collection of characteristics on all of the superheroes created by Marvel and DC comics in the last 80 years.

Let's start by creating a contingency table, which is a useful way to represent the total counts of observations that fall into each combination of the levels of categorical variables.

```{r}
# Print the first rows of the data
head(comics)

# Check levels of align
levels(comics$align)

# Check the levels of gender
levels(comics$gender)

# Create a 2-way contingency table
table(comics$align, comics$gender)
```

### Dropping levels

The contingency table from the last exercise revealed that there are some levels that have very low counts. To simplify the analysis, it often helps to drop such levels.

In R, this requires two steps: first filtering out any rows with the levels that have very low counts, then removing these levels from the factor variable with `droplevels()`. This is because the `droplevels()` function would keep levels that have just 1 or 2 counts; it only drops levels that don't exist in a dataset.

```{r}
# Assign contingency table to tab
tab <- table(comics$align, comics$gender)

# Load dplyr
library(dplyr)

# Print tab
tab

# Remove align level
comics_filtered <- comics %>%
  filter(align != "Reformed Criminals") %>%
  droplevels()

# See the result
head(comics_filtered)

# Check contingency table
table(comics_filtered$align, comics_filtered$gender)
```

### Side-by-side barcharts

While a contingency table represents the counts numerically, it's often more useful to represent them graphically.

Here you'll construct two side-by-side barcharts of the `comics` data. This shows that there can often be two or more options for presenting the same data. Passing the argument `position = "dodge"` to `geom_bar()` says that you want a side-by-side (i.e. not stacked) barchart.

```{r}
# Load ggplot2
library(ggplot2)

# Create side-by-side barchart of gender by alignment
ggplot(comics, aes(x = align, fill = gender)) + 
  geom_bar(position = "dodge")

# Create side-by-side barchart of alignment by gender
ggplot(comics, aes(x = gender, fill = align)) + 
  geom_bar(position = "dodge") +
  theme(axis.text.x = element_text(angle = 90))
```

Take a moment to toggle between the resulting plots in the plotting window.

### Question: Bar chart interpretation

<center>

![Which of the following interpretations of the bar charts to your right is not valid? *Source: DataCamp*](/Users/user/Documents/R/RProgforBus/Module7/Comics/barchartinterpretation.png){width=80%}

</center>

It's "Across all genders, `Bad` is the most common alignment."

### Video: Counts vs. proportions

[View slides.](https://drive.google.com/drive/folders/1rTSXe2HiLMbTePzcwtP4IUKEOHs-0OXY)

### Question: Conditional proportions

```{r}
tab <- table(comics$align, comics$gender)
options(scipen = 999, digits = 3) # Print fewer digits
prop.table(tab)     # Joint proportions
prop.table(tab, 2)  # Conditional on columns
```

Approximately what proportion of all female characters are good?

It's 51%. To answer this question, you needed to look at how `align` was distributed *within* each `gender.` That is, you wanted to *condition on* the `gender` variable.

### Counts vs. proportions (2)

Bar charts can tell dramatically different stories depending on whether they represent counts or proportions and, if proportions, what the proportions are conditioned on. To demonstrate this difference, you'll construct two barcharts in this exercise: one of counts and one of proportions.

```{r}
# Plot of gender by align
ggplot(comics, aes(x = align, fill = gender)) +
  geom_bar()
  
# Plot proportion of gender, conditional on align
ggplot(comics, aes(x = align, fill = gender)) + 
  geom_bar(position = "fill") +
  ylab("proportion")
```

By adding `position = "fill"` to `geom_bar()`, you are saying you want the bars to fill the entire height of the plotting window, thus displaying proportions and not raw counts.

### Video: Distribution of one variable

[View slides.](https://drive.google.com/drive/folders/1rTSXe2HiLMbTePzcwtP4IUKEOHs-0OXY)

Take your original two-way table, then sum the cells across each level of one of the variables. Since we've summed over the **margins** of the other variable, this is sometimes called a *marginal distribution*.

<center>

![Faceting vs. stacking. *Source: DataCamp*](/Users/user/Documents/R/RProgforBus/Module7/Comics/facetingvsstacking.png){width=80%}

![Areas are easier to compare in bar charts. *Source: DataCamp*](/Users/user/Documents/R/RProgforBus/Module7/Comics/piechartvsbarchart.png){width=80%}

</center>

### Marginal barchart

If you are interested in the distribution of alignment of *all* superheroes, it makes sense to construct a barchart for just that single variable.

You can improve the interpretability of the plot, though, by implementing some sensible ordering. Superheroes that are `"Neutral"` show an alignment between `"Good"` and `"Bad"`, so it makes sense to put that bar in the middle.

```{r}
# Change the order of the levels in align
comics$align <- factor(comics$align, 
                       levels = c("Bad", "Neutral", "Good"))

# Create plot of align
comics %>%
  filter(!is.na(align)) %>%
  ggplot(aes(x = align)) + 
  geom_bar()
```

### Conditional barchart

Now, if you want to break down the distribution of alignment based on gender, you're looking for conditional distributions.

You could make these by creating multiple filtered datasets (one for each gender) or by faceting the plot of alignment based on gender. As a point of comparison, we've provided your plot of the marginal distribution of alignment from the last exercise.

```{r}
# Plot of alignment broken down by gender
ggplot(comics, aes(x = align)) + 
  geom_bar() +
  facet_wrap(~ gender)
```

### Improve piechart

The piechart is a very common way to represent the distribution of a single categorical variable, but they can be more difficult to interpret than barcharts.

This is a piechart of a dataset called 'pies' that contains the favorite pie flavors of 98 people. Improve the representation of these data by constructing a barchart that is ordered in descending order of count.

```{r}
pies <- data.frame(c(rep("apple", times = 17), rep("blueberry", times = 14), rep("boston creme", times =15), rep("cherry", times =13), rep("key lime", times =16), rep("pumpkin", times =12), rep("strawberry", times =11)))
names(pies) <- "flavor"

# Create pie chart of flavor
pie(table(pies$flavor))

ggplot(pies, aes(x = flavor)) + 
  geom_bar()

# Put levels of flavor in descending order
lev <- c("apple", "key lime", "boston creme", "blueberry", "cherry", "pumpkin", "strawberry")
pies$flavor <- factor(pies$flavor, levels = lev)

# Create barchart of flavor
ggplot(pies, aes(x = flavor)) + 
  geom_bar(fill = "chartreuse") + 
  theme(axis.text.x = element_text(angle = 90))

# Alternative solution to finding levels
# lev <- unlist(select(arrange(cnt, desc(n)), flavor))
```

## Cars

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#install.packages("easypackages") # Will install and load packages if not loaded
library(easypackages)
#packages("dplyr", "ggplot2", "openintro", "gapminder", "fivethirtyeight", "downloader", "tidyverse", "tibble")
libraries("dplyr", "ggplot2", "openintro", "gapminder", "fivethirtyeight", "downloader", "tidyverse", "tibble") 
```

In this chapter, you will learn how to graphically summarize numerical data.

```{r}
library(readr)
cars <- read_csv('https://assets.datacamp.com/production/course_1796/datasets/cars04.csv')
#cars <- cars %>% 
#  mutate(msrp = as.integer(msrp))
cars[,c(9:10,12:19)] <- sapply(cars[,c(9:10,12:19)],as.integer)
```

### Video: Exploring numerical data

[View slides.](https://drive.google.com/drive/folders/1rTSXe2HiLMbTePzcwtP4IUKEOHs-0OXY)

```{r check structure of cars}
str(cars)
```

```{r dotplot}
# The most direct way to represent numerical data is a dotplot
ggplot(cars, aes(x = weight)) +
  geom_dotplot(dotsize = 0.4)
# There is zero data loss in a dotplot - you could recreate the data set perfectly from the display
```

```{r histogram}
ggplot(cars, aes(x = weight)) +
  geom_histogram()
# Because of binning, it's no longer possible to recreate the original data set
```

```{r density plot}
# A density plot avoids the unnatural step-wise nature of a histogram
ggplot(cars, aes(x = weight)) +
  geom_density()
# Use only when you have a large number of cases
```

```{r box and whisker plot}
# A more abstracted sense of the distribution
ggplot(cars, aes(x = 1, y = weight)) +
  geom_boxplot() +
  coord_flip()
```

```{r faceted histogram}
ggplot(cars, aes(x = hwy_mpg)) +
  geom_histogram() +
  facet_wrap(~pickup)
```

### Faceted histogram

In this chapter, you'll be working with the `cars` dataset, which records characteristics on all of the new models of cars for sale in the US in a certain year. You will investigate the distribution of mileage across a categorial variable, but before you get there, you'll want to familiarize yourself with the dataset.

```{r}
# Load package
library(ggplot2)

# Learn data structure
str(cars)

# Create faceted histogram
ggplot(cars, aes(x = city_mpg)) +
  geom_histogram() +
  facet_wrap(~ suv)
```

In this exercise, you faceted by the `suv` variable, but it's important to note that you can facet a plot by any categorical variable using `facet_wrap()`.

### Boxplots and density plots

The mileage of a car tends to be associated with the size of its engine (as measured by the number of cylinders). To explore the relationship between these two variables, you could stick to using histograms, but in this exercise you'll try your hand at two alternatives: the box plot and the density plot.

```{r}
# Create box plots of city mpg by ncyl
ggplot(cars, aes(x = as.factor(ncyl), y = city_mpg)) +
  geom_boxplot()
  
# Check how many possible levels of ncyl there are
unique(cars$ncyl)

# Which levels are the most common?
table(cars$ncyl)

# Filter cars with 4, 6, 8 cylinders
common_cyl <- filter(cars, ncyl %in% c(4, 6, 8))

# Create box plots of city mpg by ncyl
ggplot(common_cyl, aes(x = as.factor(ncyl), y = city_mpg)) +
  geom_boxplot()

# Create overlaid density plots for same data
ggplot(common_cyl, aes(x = city_mpg, fill = as.factor(ncyl))) +
  geom_density(alpha = .3)
```

### Compare distribution via plots

Which of the following interpretations of the plot is not valid?

It's "The variability in mileage of 8 cylinder cars is similar to the variability in mileage of 4 cylinder cars." The variability in mileage of 8 cylinder cars seem much smaller than that of 4 cylinder cars.

### Video: Distribution of one variable

[View slides.](https://drive.google.com/drive/folders/1rTSXe2HiLMbTePzcwtP4IUKEOHs-0OXY)

...Specifically a numerical variable.

```{r}
ggplot(cars, aes(x = hwy_mpg)) +
  geom_histogram()

# Adding a facet_wrap layer (faceting on a categorical value)
ggplot(cars, aes(x = hwy_mpg)) +
  geom_histogram() +
  facet_wrap(~pickup)

# Adding a filter (filtering on a numerical variable)
cars2 <- cars %>% 
  filter(eng_size < 2.0)

ggplot(cars2, aes(x = hwy_mpg)) +
  geom_histogram()

# Alternatively
cars %>% 
  filter(eng_size < 2.0) %>% 
  ggplot(aes(x = hwy_mpg)) + # Note that you don't need to specify the data frame, as we're piping in cars
  geom_histogram()

# Alternatively
cars %>% 
  filter(eng_size < 2.0) %>% 
  ggplot(aes(x = hwy_mpg)) + # Note that you don't need to specify the data frame, as we're piping in cars
  geom_histogram(binwidth = 5)
```

### Marginal and conditional histograms

Now, turn your attention to a new variable: `horsepwr.` The goal is to get a sense of the marginal distribution of this variable and then compare it to the distribution of horsepower conditional on the price of the car being less than $25,000.

You'll be making two plots using the "data pipeline" paradigm, where you start with the raw data and end with the plot.

```{r}
# Create hist of horsepwr
cars %>%
  ggplot(aes(x = horsepwr)) +
  geom_histogram() +
  xlim(c(90, 550)) +
  ylim(c(0, 50)) +
  ggtitle("Distribution of horsepower for all cars")

# Create hist of horsepwr for affordable cars
cars %>% 
  filter(msrp < 25000) %>%
  ggplot(aes(x = horsepwr)) +
  geom_histogram() +
  xlim(c(90, 550)) +
  ylim(c(0, 50)) +
  ggtitle("Distribution of horsepower for affordable cars")
```

### Question: Marginal and conditional histograms interpretation

Observe the two histograms in the plotting window and decide which of the following is a valid interpretation.

It's "The highest horsepower car in the less expensive range has just under 250 horsepower."

### Three binwidths

Before you take these plots for granted, it's a good idea to see how things change when you alter the binwidth. The binwidth determines how smooth your distribution will appear: the smaller the binwidth, the more jagged your distribution becomes. It's good practice to consider several binwidths in order to detect different types of structure in your data.

```{r histograms with different bin widths}
# Create hist of horsepwr with binwidth of 3
cars %>%
  ggplot(aes(x = horsepwr)) +
  geom_histogram(binwidth = 3) +
  ggtitle("binwidth = 3")

# Create hist of horsepwr with binwidth of 30
cars %>%
  ggplot(aes(x = horsepwr)) +
  geom_histogram(binwidth = 30) +
  ggtitle("binwidth = 30")

# Create hist of horsepwr with binwidth of 60
cars %>%
  ggplot(aes(x = horsepwr)) +
  geom_histogram(binwidth = 60) +
  ggtitle("binwidth = 60")

```

Be sure to toggle back and forth in the plots pane to compare the histograms.

### Question: Three binwidths interpretation

What feature is present in Plot A that's not found in B or C?

It's "There is a tendency for cars to have horsepower right at 200 or 300 horsepower." Plot A is the only histogram that shows the count for cars with exactly 200 and 300 horsepower.

### Video: Box plots

[View slides.](https://drive.google.com/drive/folders/1rTSXe2HiLMbTePzcwtP4IUKEOHs-0OXY)

### Box plots for outliers

In addition to indicating the center and spread of a distribution, a box plot provides a graphical means to detect outliers. You can apply this method to the `msrp` column (manufacturer's suggested retail price) to detect if there are unusually expensive or cheap cars.

```{r}
# Construct box plot of msrp
cars %>%
  ggplot(aes(x = 1, y = msrp)) +
  geom_boxplot()

# Exclude outliers from data
cars_no_out <- cars %>%
  filter(msrp < 100000)

# Construct box plot of msrp using the reduced dataset
cars_no_out %>%
  ggplot(aes(x = 1, y = msrp)) +
  geom_boxplot()
```

Be sure to toggle back and forth in the plots pane to compare the box plots.

### Plot selection

Consider two other columns in the `cars` dataset: `city_mpg` and `width.` Which is the most appropriate plot for displaying the important features of their distributions? Remember, both density plots and box plots display the central tendency and spread of the data, but the box plot is more robust to outliers.

```{r}
# Create plot of city_mpg
cars %>%
  ggplot(aes(x = city_mpg)) +
  geom_density()

cars %>%
  ggplot(aes(x = 1, y = city_mpg)) +
  geom_boxplot()

# Create plot of width
cars %>%
  ggplot(aes(x = width)) +
  geom_density()

cars %>%
  ggplot(aes(x = 1, y = width)) +
  geom_boxplot()
```

Because the `city_mpg` variable has a much wider range with its outliers, it's best to display its distribution as a box plot.

### Video: Visualization in higher dimensions

[View slides.](https://drive.google.com/drive/folders/1rTSXe2HiLMbTePzcwtP4IUKEOHs-0OXY)

```{r}
ggplot(cars, aes(x = msrp)) +
  geom_density() +
  facet_grid(pickup ~ rear_wheel)

# Add labels to aid understanding
ggplot(cars, aes(x = msrp)) +
  geom_density() +
  facet_grid(pickup ~ rear_wheel, labeller = label_both)

# There's very few rear wheel pickups and front wheel pickups
table(cars$rear_wheel, cars$pickup) # table(rows, columns)
```

### 3 variable plot

Faceting is a valuable technique for looking at several conditional distributions at the same time. If the faceted distributions are laid out in a grid, you can consider the association between a variable and two others, one on the rows of the grid and the other on the columns.

```{r}
# Facet hists using hwy mileage and ncyl
common_cyl %>%
  ggplot(aes(x = hwy_mpg)) +
  geom_histogram() +
  facet_grid(ncyl ~ suv, labeller = label_both) +
  ggtitle("Mileage by suv and ncyl")
```

### Question: Interpret 3 var plot

Which of the following interpretations of the plot is valid?

It's "Across both SUVs and non-SUVs, mileage tends to decrease as the number of cylinders increases."

## Gapminder

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#install.packages("easypackages") # Will install and load packages if not loaded
library(easypackages)
#packages("dplyr", "ggplot2", "openintro", "gapminder", "fivethirtyeight", "downloader", "tidyverse", "tibble")
libraries("dplyr", "ggplot2", "openintro", "gapminder", "fivethirtyeight", "downloader", "tidyverse", "tibble") 
```

Now that we've looked at exploring categorical and numerical data, you'll learn some useful statistics for describing distributions of data.

### Video: Measures of center

[View slides.](https://drive.google.com/drive/folders/1rTSXe2HiLMbTePzcwtP4IUKEOHs-0OXY)

### Question: Choice of center measure
The choice of measure for center can have a dramatic impact on what we consider to be a typical observation, so it is important that you consider the shape of the distribution before deciding on the measure.

<center>

![Which set of measures of central tendency would be worst for describing the two distributions shown here? *Source: DataCamp*](/Users/user/Documents/R/RProgforBus/Module7/Gapminder/choiceofcentermeasure.png){width=80%}

</center>

It's "A: mean, B: mode".

### Calculate center measures

Throughout this chapter, you will use data from `gapminder`, which tracks demographic data in countries of the world over time. To learn more about it, you can bring up the help file with `?gapminder`.

For this exercise, focus on how the life expectancy differs from continent to continent. This requires that you conduct your analysis not at the country level, but aggregated up to the continent level. This is made possible by the one-two punch of `group_by()` and `summarize()`, a very powerful syntax for carrying out the same analysis on different subsets of the full dataset.

```{r}
# Create dataset of 2007 data
gap2007 <- filter(gapminder, year == 2007)

# Compute groupwise mean and median lifeExp
gap2007 %>%
  group_by(continent) %>%
  summarize(mean(lifeExp),
            median(lifeExp))

# Generate box plots of lifeExp for each continent
gap2007 %>%
  ggplot(aes(x = continent, y = lifeExp)) +
  geom_boxplot()
```

### Video: Measures of variability

[View slides.](https://drive.google.com/drive/folders/1rTSXe2HiLMbTePzcwtP4IUKEOHs-0OXY)


```{r}
x <- head(round(gap2007$lifeExp), 11)

x - mean(x)

sum(x - mean(x)) # which is close to 0

sum((x - mean(x))^2) # which will keep getting bigger the more data you add

n <- 11
sum((x - mean(x))^2)/n

sum((x - mean(x))^2)/(n-1) # The sample variance
var(x) # R's built-in function

sqrt(sum((x - mean(x))^2)/(n-1))
sd(x)
# which is more commonly used than the...
summary(x)
IQR(x)
# However SD is affected by extreme values, unlike IQR, which is better to use with large skew and extreme outliers
```

Choice of spread measure
The choice of measure for spread can dramatically impact how variable we consider our data to be, so it is important that you consider the shape of the distribution before deciding on the measure.

<center>

![Which set of measures of spread would be worst for describing the two distributions shown here? *Source: DataCamp*](/Users/user/Documents/R/RProgforBus/Module7/Gapminder/choiceofcentermeasure.png){width=80%}

</center>

It's "A: Variance, B: Range". Notice the high peak of A and the considerable width of it. What does that tell you about its variance?

### Calculate spread measures

Let's extend the powerful `group_by()` and `summarize()` syntax to measures of spread. If you're unsure whether you're working with symmetric or skewed distributions, it's a good idea to consider a robust measure like IQR in addition to the usual measures of variance or standard deviation.

```{r}
# Compute groupwise measures of spread
gap2007 %>%
  group_by(continent) %>%
  summarize(sd(lifeExp),
            IQR(lifeExp),
            n())

# Generate overlaid density plots
gap2007 %>%
  ggplot(aes(x = lifeExp, fill = continent)) +
  geom_density(alpha = 0.3)
```

### Choose measures for center and spread

<center>

![Consider the density plots shown here. What are the most appropriate measures to describe their centers and spreads? In this exercise, you'll select the measures and then calculate them. *Source: DataCamp*](/Users/user/Documents/R/RProgforBus/Module7/Gapminder/choosemeasuresforcenterandspread.png){width=80%}

</center>

```{r}
# Compute stats for lifeExp in Americas
gap2007 %>%
  filter(continent == "Americas") %>%
  summarize(mean(lifeExp),
            sd(lifeExp))

# Compute stats for population
gap2007 %>%
  summarize(median(pop),
            IQR(pop))
```

Like mean and standard deviation, median and IQR measure the central tendency and spread, respectively, but are robust to outliers and non-normal data.

### Video: Shape and transformations

[View slides.](https://drive.google.com/drive/folders/1rTSXe2HiLMbTePzcwtP4IUKEOHs-0OXY)

### Describe the shape

To build some familiarity with distributions of different shapes, consider the four that are plotted here. 

<center>

![Which of the following options does the best job of describing their shape in terms of modality and skew/symmetry? *Source: DataCamp*](/Users/user/Documents/R/RProgforBus/Module7/Gapminder/describetheshape.png){width=80%}

</center>

It's "A: unimodal left-skewed; B: unimodal symmetric; C: unimodal right-skewed, D: bimodal symmetric."

### Transformations

Highly skewed distributions can make it very difficult to learn anything from a visualization. Transformations can be helpful in revealing the more subtle structure.

Here you'll focus on the population variable, which exhibits strong right skew, and transform it with the natural logarithm function (`log()` in R).

```{r}
# Create density plot of old variable
gap2007 %>%
  ggplot(aes(x = pop)) +
  geom_density()

# Transform the skewed pop variable
gap2007 <- gap2007 %>%
  mutate(log_pop = log(pop))

# Create density plot of new variable
gap2007 %>%
  ggplot(aes(x = log(pop))) +
  geom_density()
```

### Video: Outliers

[View slides.](https://drive.google.com/drive/folders/1rTSXe2HiLMbTePzcwtP4IUKEOHs-0OXY)

### Identify outliers

Consider the distribution, shown here, of the life expectancies of the countries in Asia. The box plot identifies one clear outlier: a country with a notably low life expectancy. Do you have a guess as to which country this might be? Test your guess in the console using either `min()` or `filter()`, then proceed to building a plot with that country removed.

```{r}
# Filter for Asia, add column indicating outliers
gap_asia <- gap2007 %>%
  filter(continent == "Asia") %>%
  mutate(is_outlier = lifeExp < 50)

# Remove outliers, create box plot of lifeExp
gap_asia %>%
  filter(!is_outlier) %>%
  ggplot(aes(x = 1, y = lifeExp)) +
  geom_boxplot()
```

## Email

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#install.packages("easypackages") # Will install and load packages if not loaded
library(easypackages)
#packages("dplyr", "ggplot2", "openintro", "gapminder", "fivethirtyeight", "downloader", "tidyverse", "tibble")
libraries("dplyr", "ggplot2", "openintro", "gapminder", "fivethirtyeight", "downloader", "tidyverse", "tibble") 
```

Apply what you've learned to explore and summarize a real world dataset in this case study of email spam. We will use the `email` data set in the `openintro` package.

### Video: Introducing the data

[View slides.](https://drive.google.com/drive/folders/1rTSXe2HiLMbTePzcwtP4IUKEOHs-0OXY)


```{r}
email <- email %>% 
  mutate(spam = as.factor(spam))
levels(email$spam) <- c("not-spam", "spam")
head(email)
str(email)
```

### Spam and num_char

Is there an association between spam and the length of an email? You could imagine a story either way:

- *Spam is more likely to be a short message tempting me to click on a link*, or

- *My normal email is likely shorter since I exchange brief emails with my friends all the time.*

Here, you'll use the `email` dataset to settle that question. Begin by bringing up the help file and learning about all the variables with `?email`.

As you explore the association between spam and the length of an email, use this opportunity to try out linking a `dplyr` chain with the layers in a `ggplot2` object.

```{r}
# Compute summary statistics
email %>%
  group_by(spam) %>%
  summarize(median(num_char),
  IQR(num_char))

# Create plot
email %>%
  mutate(log_num_char = log(num_char)) %>%
  ggplot(aes(x = spam, y = log_num_char)) +
  geom_boxplot()
```

You'll interpret this plot in the next exercise.

### Spam and num_char interpretation

Which of the following interpretations of the plot is valid?

It's "The median length of not-spam emails is greater than that of spam emails."

### Spam and !!!

Let's look at a more obvious indicator of spam: exclamation marks. `exclaim_mess` contains the number of exclamation marks in each message. Using summary statistics and visualization, see if there is a relationship between this variable and whether or not a message is spam.

Experiment with different types of plots until you find one that is the most informative. Recall that you've seen:

- Side-by-side box plots
- Faceted histograms
- Overlaid density plots

```{r}
# Compute center and spread for exclaim_mess by spam
email %>%
  group_by(spam) %>%
  summarize(median(exclaim_mess),
            IQR(exclaim_mess))


# Create plot for spam and exclaim_mess
email %>%
  mutate(log_exclaim_mess = log(exclaim_mess + 0.01)) %>%
  ggplot(aes(x = 1, y = log_exclaim_mess)) +
  geom_boxplot() +
  facet_wrap(~ spam)

# Alternative plot: side-by-side box plots
email %>%
  mutate(log_exclaim_mess = log(exclaim_mess + 0.01)) %>%
  ggplot(aes(x = log_exclaim_mess)) +
  geom_histogram() +
  facet_wrap(~ spam)

# Alternative plot: Overlaid density plots
email %>%
  mutate(log_exclaim_mess = log(exclaim_mess + .01)) %>%
  ggplot(aes(x = log_exclaim_mess, fill = spam)) +
  geom_density(alpha = 0.3)
```

### Spam and !!! interpretation

Which interpretation of these faceted histograms is not correct?

It's "There are more cases of spam in this dataset than not-spam."

### Video: Check-in 1

[View slides.](https://drive.google.com/drive/folders/1rTSXe2HiLMbTePzcwtP4IUKEOHs-0OXY)

### Collapsing levels

If it was difficult to work with the heavy skew of `exclaim_mess`, the number of images attached to each email (`image`) poses even more of a challenge. Run the following code at the console to get a sense of its distribution:

```{r}
table(email$image)
```

Recall that this tabulates the number of cases in each category (so there were 3811 emails with 0 images, for example). Given the very low counts at the higher number of images, let's **collapse** `image` into a categorical variable that indicates whether or not the email had at least one image. In this exercise, you'll create this new variable and explore its association with spam.

```{r}
# Create plot of proportion of spam by image
email %>%
  mutate(has_image = image > 0) %>%
  ggplot(aes(x = has_image, fill = spam)) +
  geom_bar(position = "fill")
```

Let's interpret this plot in the next exercise.

### Question: Image and spam interpretation

Which of the following interpretations of the plot is valid?

It's "An email without an image is more likely to be not-spam than spam."

### Data Integrity

In the process of exploring a dataset, you'll sometimes come across something that will lead you to question how the data were compiled. For example, the variable `num_char` contains the number of characters in the email, in thousands, so it could take decimal values, but it certainly shouldn't take negative values.

You can formulate a test to ensure this variable is behaving as we expect:

```{r}
email$num_char < 0
```

If you run this code at the console, you'll get a long vector of logical values indicating for each case in the dataset whether that condition is `TRUE`. Here, the first 1000 values all appear to be `FALSE`. To verify that all of the cases indeed have non-negative values for `num_char`, we can take the sum of this vector:

```{r}
sum(email$num_char < 0)
```

This is a handy shortcut. When you do arithmetic on logical values, R treats `TRUE` as `1` and `FALSE` as `0.` Since the sum over the whole vector is zero, you learn that every case in the dataset took a value of `FALSE` in the test. That is, the `num_char` column is behaving as we expect and taking only non-negative values.

```{r}
# Test if images count as attachments
sum(email$image > email$attach)
```

Since image is never greater than attach, we can infer that images are counted as attachments.

### Answering questions with chains

When you have a specific question about a dataset, you can find your way to an answer by carefully constructing the appropriate chain of R code. For example, consider the following question:

> *"Within non-spam emails, is the typical length of emails shorter for those that were sent to multiple people?"*

This can be answered with the following chain:

```{r}
email %>%
   filter(spam == "not-spam") %>%
   group_by(as.factor(to_multiple)) %>%
   summarize(median(num_char))

email %>%
   filter(spam == "not-spam") %>%
   group_by(to_multiple) %>%
   summarise(median(num_char))
str(email)
```

The code makes it clear that you are using `num_char` to measure the length of an email and `median()` as the measure of what is typical. If you run this code, you'll learn that the answer to the question is "yes": the typical length of non-spam sent to multiple people is a bit lower than those sent to only one person.

This chain concluded with summary statistics, but others might end in a plot; it all depends on the question that you're trying to answer.

```{r}
# Question 1
email %>%
  filter(dollar > 0) %>%
  group_by(spam) %>%
  summarize(mean(dollar))

# Question 2
email %>%
  filter(dollar > 10) %>%
  ggplot(aes(x = spam)) +
  geom_bar()
```

### Video: Check-in 2

[View slides.](https://drive.google.com/drive/folders/1rTSXe2HiLMbTePzcwtP4IUKEOHs-0OXY)

We're now moving from '**Exploratory graphics**' (aiming to find out what's there) to '**Expository graphics**' (aiming to you seek to explain, describe or communicate a particular idea).

### What's in a number?

Turn your attention to the variable called `number.` Read more about it by pulling up the help file with `?email`.

To explore the association between this variable and `spam`, select and construct an informative plot. For illustrating relationships between categorical variables, you've seen

- Faceted barcharts
- Side-by-side barcharts
- Stacked and normalized barcharts.

Let's practice constructing a faceted barchart.


```{r}
# Reorder levels
email$number_reordered <- factor(email$number, levels = c("none"
, "small", "big"))

# Construct plot of number_reordered
ggplot(email, aes(x = number_reordered)) +
  geom_bar() +
  facet_wrap(~spam)
```

### What's in a number interpretation

Which of the following interpretations of the plot is not valid?

It's "Given that an email contains no number, it is more likely to be spam."

### Video: Conclusion

[View slides.](https://drive.google.com/drive/folders/1rTSXe2HiLMbTePzcwtP4IUKEOHs-0OXY)

## Challenge

Via DataCamp

Once you've started learning tools for data manipulation and visualization like dplyr and ggplot2, this course gives you a chance to use them in action on a real dataset. You'll explore the historical voting of the United Nations General Assembly, including analyzing differences in voting between countries, across time, and among international issues. In the process you'll gain more practice with the dplyr and ggplot2 packages, learn about the broom package for tidying model output, and experience the kind of start-to-finish exploratory analysis common in data science.

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#install.packages("easypackages") # Will install and load packages if not loaded
library(easypackages)
#packages("dplyr", "ggplot2", "openintro", "gapminder", "fivethirtyeight", "downloader", "tidyverse", "tibble")
libraries("dplyr", "ggplot2", "openintro", "gapminder", "fivethirtyeight", "downloader", "tidyverse", "tibble")
```

## Solutions 1: Data cleaning and summarizing with dplyr

The best way to learn data wrangling skills is to apply them to a specific case study. Here you'll learn how to clean and filter the United Nations voting dataset using the dplyr package, and how to summarize it into smaller, interpretable units.

```{r}
url <- "https://github.com/datasciencelabs/data/raw/master/rawvotingdata13.tab"
filename <- basename(url)
if (!file.exists(filename)) download(url,destfile=filename)
votes <-read.delim("rawvotingdata13.tab", header = TRUE, sep = "\t",
quote = "")
votes <- votes %>% 
  filter(session != 19)
```

### Video: The United Nations Voting Dataset

[View slides.](https://drive.google.com/drive/folders/1rTSXe2HiLMbTePzcwtP4IUKEOHs-0OXY)

```{r}
str(votes)
head(votes)
```

```{r, echo=T, results = 'hide'}
votes <- votes %>% 
  mutate(year = session + 1945)
```

### Filtering rows

The vote column in the dataset has a number that represents that country's vote:

- 1 = Yes
- 2 = Abstain
- 3 = No
- 8 = Not present
- 9 = Not a member

One step of data cleaning is removing observations (rows) that you're not interested in. In this case, you want to remove "Not present" and "Not a member".

```{r}
unique(votes$vote)
```

```{r, echo=T, results = 'hide'}
# Filter for votes that are "yes", "abstain", or "no"
votes %>% 
  filter(vote <= 3)
```

### Adding a year column

The next step of data cleaning is manipulating your variables (columns) to make them more informative.

In this case, you have a `session` column that is hard to interpret intuitively. But since the UN started voting in 1946, and holds one session per year, you can get the year of a UN resolution by adding 1945 to the `session` number.

```{r, echo=T, results = 'hide'}
# Add another %>% step to add a year column
votes %>%
  filter(vote <= 3) %>%
  mutate(year = session + 1945)
```

### Adding a country column

The country codes in the `ccode` column are what's called [**Correlates of War codes**](https://correlatesofwar.org/data-sets/cow-country-codes). This isn't ideal for an analysis, since you'd like to work with recognizable country names.

You can use the `countrycode` package to translate. For example:

```{r}
library(countrycode)

# Translate the country code 2
countrycode(2, "cown", "country.name")

# Translate the country code 703
countrycode(703, "cown", "country.name")

# Translate multiple country codes
countrycode(c(2, 20, 40), "cown", "country.name")
```

```{r, include=FALSE}
url <- "https://correlatesofwar.org/data-sets/cow-country-codes/cow-country-codes"
filename <- basename(url)
if (!file.exists(filename)) download(url,destfile=filename)
cccodes <- read.csv(filename)
```

```{r, echo=T, results = 'hide'}
# Convert country code 100
countrycode(100, "cown", "country.name")

# Add a country column within the mutate: votes_processed
votes_processed <- votes %>%
  filter(vote <= 3) %>%
  mutate(year = session + 1945,
  country = countrycode(ccode, "cown", "country.name"))
votes_processed$country[votes_processed$ccode == "260"] <- "German Federal Republic"
```

### Video: Grouping and summarizing

[View slides.](https://drive.google.com/drive/folders/1rTSXe2HiLMbTePzcwtP4IUKEOHs-0OXY)

### Summarizing the full dataset

In this analysis, you're going to focus on "% of votes that are yes" as a metric for the "agreeableness" of countries.

You'll start by finding this summary for the entire dataset: the fraction of all votes in their history that were "yes". Note that within your call to `summarize()`, you can use `n()` to find the total number of votes and `mean(vote == 1)` to find the fraction of "yes" votes.


```{r}
head(votes_processed)

votes_processed %>% 
  summarize(total = n(),
            percent_yes = mean(vote == 1))
```

### Summarizing by year

The `summarize()` function is especially useful because it can be used within *groups*.

For example, you might like to know how much the average "agreeableness" of countries changed from year to year. To examine this, you can use `group_by()` to perform your summary not for the entire dataset, but within each year.

```{r}
by_year <- votes_processed %>%
  group_by(year) %>% 
  summarize(total = n(),
            percent_yes = mean(vote == 1))
```

The `group_by()` function must go before your call to `summarize()` when you're trying to perform your summary within groups.

### Summarizing by country

In the last exercise, you performed a summary of the votes within each year. You could instead `summarize()` within each country, which would let you compare voting patterns between countries.

```{r}
# Summarize by country: by_country
by_country <- votes_processed %>%
  group_by(country) %>%
  summarize(total = n(),
            percent_yes = mean(vote == 1))
```

### Video: Sorting and filtering summarized data

[View slides.](https://drive.google.com/drive/folders/1rTSXe2HiLMbTePzcwtP4IUKEOHs-0OXY)

<center>

![Transforming tidy data. *Source: DataCamp*](/Users/user/Documents/R/RProgforBus/Module7/Challenge8/transformingtidydata.png){width=75%}

</center>

### Sorting by percentage of "yes" votes

Now that you've summarized the dataset by country, you can start examining it and answering interesting questions.

For example, you might be especially interested in the countries that voted "yes" least often, or the ones that voted "yes" most often.

```{r}
# Print first few entries of the by_country dataset
head(by_country)

# Sort in ascending order of percent_yes
by_country %>%
arrange(percent_yes)

# Now sort in descending order
by_country %>%
arrange(desc(percent_yes))
```

### Filtering summarized output

In the last exercise, you may have noticed that the country that voted least frequently, Zanzibar, had only 2 votes in the entire dataset. You certainly can't make any substantial conclusions based on that data!

Typically in a progressive analysis, when you find that a few of your observations have very little data while others have plenty, you set some threshold to filter them out.

```{r}
# Filter out countries with fewer than 100 votes
by_country %>%
filter(total >= 100) %>%
  arrange(percent_yes)
```

---

## Solutions 2: Visualization with ggplot2

Once you've cleaned and summarized data, you'll want to visualize them to understand trends and extract insights. Here you'll use the ggplot2 package to explore trends in United Nations voting within each country over time.

### Video: Visualization with ggplot2

[View slides.](https://drive.google.com/drive/folders/1rTSXe2HiLMbTePzcwtP4IUKEOHs-0OXY)

### Choosing an aesthetic

You're going to create a line graph to show the trend over time of how many votes are "yes".

Which of the following aesthetics should you map the `year` variable to?

It's"X-axis".

To plot a line graph to show the trend over time, the `year` variable should be on the x-axis.

```{r}
# Create line plot
ggplot(by_year, aes(x = year, y = percent_yes)) +
  geom_line()
```

### Other ggplot2 layers

A line plot is one way to display this data. You could also choose to display it as a scatter plot, with each year represented as a single point. This requires changing the layer (i.e. `geom_line()` to `geom_point()`).

You can also add additional layers to your graph, such as a smoothing curve with `geom_smooth()`.

```{r}
# Change to scatter plot and add smoothing curve
ggplot(by_year, aes(year, percent_yes)) +
  geom_point() +
  geom_smooth()
```

### Video: Visualizing by country

[View slides.](https://drive.google.com/drive/folders/1rTSXe2HiLMbTePzcwtP4IUKEOHs-0OXY)

```{r}
by_year_country <- votes_processed %>%
  group_by(year, country) %>% 
  summarize(total = n(),
            percent_yes = mean(vote == 1))

us_france <- by_year_country %>% 
  filter(country %in% c("United States", "France"))
us_france

ggplot(us_france, aes(x = year, y = percent_yes, color = country)) +
  geom_line() +
  ylim(0,1)
```

### Summarizing by year and country

You're more interested in trends of voting within specific countries than you are in the overall trend. So instead of summarizing just by year, summarize by both year *and* country, constructing a dataset that shows what fraction of the time each country votes "yes" in each year.

```{r}
by_year_country <- votes_processed %>%
  group_by(year, country) %>% 
  summarize(total = n(),
            percent_yes = mean(vote == 1))
```

Let's make some plots using this new dataset in the next exercise.

### Plotting just the UK over time

Now that you have the percentage of time that each country voted "yes" within each year, you can plot the trend for a particular country. In this case, you'll look at the trend for just the United Kingdom.

This will involve using `filter()` on your data before giving it to `ggplot2`.

```{r}
# Create a filtered version: UK_by_year
UK_by_year <- by_year_country %>%
filter(country %in% c("United Kingdom"))

# Line plot of percent_yes over time for UK only
ggplot(UK_by_year, aes(x = year, y = percent_yes)) +
  geom_line()
```

```{r}
# Create a filtered version: UK_by_year
Kg_by_year <- by_year_country %>%
filter(country %in% c("Kyrgyzstan"))

# Line plot of percent_yes over time for UK only
ggplot(Kg_by_year, aes(x = year, y = percent_yes)) +
  geom_line() +
  ylim(0,1)
```

### Plotting multiple countries

Plotting just one country at a time is interesting, but you really want to compare trends `between` countries. For example, suppose you want to compare voting trends for the United States, the UK, France, and India.

You'll have to filter to include all `four` of these countries and use another aesthetic (not just x- and y-axes) to distinguish the countries on the resulting visualization. Instead, you'll use the color aesthetic to represent different countries.

```{r}
# Vector of four countries to examine
countries <- c("United States", "United Kingdom",
               "France", "India")

# Filter by_year_country: filtered_4_countries
filtered_4_countries <- by_year_country %>%
filter(country %in% countries)

# Line plot of % yes in four countries
ggplot(filtered_4_countries, aes(x = year, y = percent_yes, color = country)) +
  geom_line()
```

### Video: Faceting by country

[View slides.](https://drive.google.com/drive/folders/1rTSXe2HiLMbTePzcwtP4IUKEOHs-0OXY)

### Faceting the time series

Now you'll take a look at six countries. While in the previous exercise you used color to represent distinct countries, this gets a little too crowded with six.

Instead, you will facet, giving each country its own sub-plot. To do so, you add a `facet_wrap()` step after all of your layers.

```{r}
# Vector of six countries to examine
countries <- c("United States", "United Kingdom",
               "France", "Japan", "Brazil", "India")

# Filtered by_year_country: filtered_6_countries
filtered_6_countries <- by_year_country %>%
filter(country %in% countries)

# Line plot of % yes over time faceted by country
ggplot(filtered_6_countries, aes(x = year, y = percent_yes)) +
  geom_line() +
  facet_wrap(~country)
```

### Faceting with free y-axis

In the previous plot, all six graphs had the same axis limits. This made the changes over time hard to examine for plots with relatively little change.

Instead, you may want to let the plot choose a different y-axis for each facet.

```{r}
# Line plot of % yes over time faceted by country
ggplot(filtered_6_countries, aes(year, percent_yes)) +
  geom_line() +
  facet_wrap(~ country, scales="free_y")
```

### Choose your own countries

The purpose of an exploratory data analysis is to ask questions and answer them with data. Now it's your turn to ask the questions.

You'll choose some countries whose history you are interested in and add them to the graph. If you want to look up the full list of countries, enter by_country$country in the console.

```{r}
# Add three more countries to this list
countries <- c("United States", "United Kingdom",
               "France", "Japan", "Brazil", "India", "Kyrgyzstan", 
               "Georgia", "Germany")

# Filtered by_year_country: filtered_countries
filtered_countries <- by_year_country %>%
  filter(country %in% countries)

# Line plot of % yes over time faceted by country
ggplot(filtered_countries, aes(year, percent_yes)) +
  geom_line() +
  facet_wrap(~ country, scales = "free_y")
```

---

## Solutions 3: Tidy modeling with broom

While visualization helps you understand one country at a time, statistical modeling lets you quantify trends across many countries and interpret them together. Here you'll learn to use the tidyr, purrr, and broom packages to fit linear models to each country, and understand and compare their outputs.

### Video: Linear regression

[View slides.](https://drive.google.com/drive/folders/1rTSXe2HiLMbTePzcwtP4IUKEOHs-0OXY)



